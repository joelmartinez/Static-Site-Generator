Title: The AI Breadline 
Date: 2025-08-07  
Published: true  
Hero: /posts/ai-breadline-hero.png  

Here's a familiar pattern I’ve seen play out more than once. Recently, [Anthropic reduced Claude’s usage limits](https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul/) after someone started consuming way more resources than expected. That’s understandable. When one user is burning through disproportionate compute, any platform is going to have to draw a line. But it's also a moment worth noting… a small sign that the period of wide-open access may be entering a new phase.

All of this is happening just as [GPT-5 is on the verge of release](https://www.reuters.com/business/retail-consumer/openais-long-awaited-gpt-5-model-nears-release-2025-08-06/). The buzz is loud, and expectations are high. It’s being treated as a major leap forward. And at the same time, I’m running into unexpected behavior in tools like GitHub Copilot's coding agent. Just last night it just stopped responding to pull request comments asking for changes. Not an error, not a warning, just silence. I'm sure it's a transient issue, but that sort of thing gets my attention. These tools are slowly embedding themselves into how we work and collaborate as they continue getting better and better; and while it’s exciting, it’s also a dependency. When a tool fails, disappears, or changes overnight, we don’t always have a plan B if we're not mindful about the way we work.

I’ve seen this kind of shift before. Twitter once had an API that helped a generation of developers build useful apps and businesses. Then came the caps and restrictions. Facebook enabled game developers to thrive through its early notification system. Then they shut it down after users complained about spam. Instagram creators built audiences and were later asked to pay to reach them through monetizable ads.

This cycle of open access, rapid growth, some degree of abuse, then restriction comes around more often than we’d like to admit. [Cory Doctorow coined the term “enshittification” to describe it](https://en.wikipedia.org/wiki/Enshittification). The idea is that platforms often start out serving users and creators, then eventually reorganize to serve themselves.

Now we get to see whether AI platforms follow the same path.

The past few years have felt like a renaissance. Open models, generous limits, and a growing community of independent developers building new things. But already you can see signs of stratification. Usage tiers, geographic restrictions, performance bottlenecks. These may not be red flags, but they are reminders that the landscape is still shifting ... even as [OpenAI introduces an actually-free and open model](https://openai.com/index/introducing-gpt-oss/).

Those who dive in early may find themselves in a difficult spot. They could wake up to find their core workflow locked behind a pricing tier that didn’t exist before. Or that a crucial API has been deprecated. Or that something they rely on just stops working, without explanation. I wrote recently about how [passion can be easy to exploit](/2025/6/starving-artists/). This feels related. People pour themselves into building something on top of a tool they trust, only to find the terms have changed after they’ve already committed.

If you’re using these tools — OpenAI, Anthropic, Midjourney, Copilot, any of them — it’s worth asking a few questions early. What would it take to move away? Is there an alternative? What happens if this tool becomes too expensive or just less useful over time? None of this means you shouldn’t use these platforms. It just means you should think about what happens next before you find yourself on the virtual breadline asking for crumbs.
